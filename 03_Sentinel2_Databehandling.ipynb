{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples for demonstrating different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xa\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure # We are going to rescale the image\n",
    "import sklearn as skl\n",
    "from sklearn.cluster import KMeans # Unsupervised learning\n",
    "from sklearn.neural_network import MLPClassifier # Supervised learning\n",
    "from matplotlib.colors import ListedColormap # For colourmap\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now imported some libraries and will load some Sentinel 2 OpenDAP NetCDF\n",
    "data from https://satellittdata.no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://nbstds.met.no/thredds/dodsC/NBS/S2A/2021/07/14/S2A_MSIL1C_20210714T105031_N0301_R051_T33WWR_20210714T130146.nc'\n",
    "dset = xa.open_dataset(url+'#fillmismatch') # opening OpenDAP NetCDF dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having opened the dataset we can how have a look at the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it contains coordinates, variables, and attributes. We can for\n",
    "instance take a closer look at the time coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dset.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the B2 data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dset.B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is B2?**\n",
    "\n",
    "We can plot B2 to see it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# East - west\n",
    "xmin = 9000\n",
    "xmax = -1\n",
    "\n",
    "# North - south\n",
    "ymin = 0\n",
    "ymax = 2000\n",
    "\n",
    "plt.figure()\n",
    "view =dset.B2[0,ymin:ymax,xmin:xmax]\n",
    "view.plot(cmap='Greys',vmax=1000)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dset.TCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = np.asarray(\n",
    "            [dset.lon[ymin,xmin].data, dset.lon[ymin,xmax].data,\n",
    "            dset.lat[ymax,xmax].data, dset.lat[ymin,xmin].data]\n",
    "         ) # To get the axis labels correct we define an extent\n",
    "\n",
    "#print('lon and lat',(extent)) # These are the latitudes and longitudes\n",
    "n=0\n",
    "# Reading in some parts of the r b g bands\n",
    "b = dset.B2[n,ymin:ymax,xmin:xmax]/float(dset.attrs['QUANTIFICATION_VALUE'])\n",
    "g = dset.B3[n,ymin:ymax,xmin:xmax]/float(dset.attrs['QUANTIFICATION_VALUE'])\n",
    "r = dset.B4[n,ymin:ymax,xmin:xmax]/float(dset.attrs['QUANTIFICATION_VALUE'])\n",
    "\n",
    "P0, P1 = (0, 0.15) # These are the percentages we are going to rescale on \n",
    "\n",
    "# Rescaling the exposures using scikit-image \n",
    "r = exposure.rescale_intensity(r,in_range=(P0,P1))\n",
    "g = exposure.rescale_intensity(g,in_range=(P0,P1))\n",
    "b = exposure.rescale_intensity(b,in_range=(P0,P1))\n",
    "\n",
    "# Making the RGB image\n",
    "rgb = np.dstack((r,g,b))\n",
    "\n",
    "# Clipping it\n",
    "rgb[rgb>1]=1.0\n",
    "\n",
    "\n",
    "# Plotting the RGB image\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(rgb, interpolation='none', aspect='auto', extent = extent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized difference vegetation index (NDVI)\n",
    "Is a measure for how much vegitation there is in a pixel. More information can be found in the book (10.6), \n",
    "https://custom-scripts.sentinel-hub.com/sentinel-2/ndvi/\n",
    "and\n",
    "https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index\n",
    "\n",
    "It is given by:\n",
    "$\\text{NDVI} = \\frac{\\textrm{NIR}-\\textrm{RED}}{\\textrm{NIR}+\\textrm{RED}}$\n",
    "\n",
    "which for Sentinel-2 becomes:\n",
    "\n",
    "$\\text{NDVI} = \\frac{\\textrm{B8}-\\textrm{B4}}{\\textrm{B8}+\\textrm{B4}}$\n",
    "\n",
    "We are now going to test it, though we are using L1C data. Normally one would use L2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (dset.B8[n,ymin:ymax,xmin:xmax] -dset.B4[n,ymin:ymax,xmin:xmax])/(dset.B8[n,ymin:ymax,xmin:xmax] +dset.B4[n,ymin:ymax,xmin:xmax])\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(ndvi, interpolation='none', aspect='auto', extent = extent)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized difference water index (NDWI)\n",
    "Measures how much water there is in the pixel as part of a water body.  More information can be found at:\n",
    "https://custom-scripts.sentinel-hub.com/sentinel-2/ndwi/\n",
    "og \n",
    "https://en.wikipedia.org/wiki/Normalized_difference_water_index\n",
    "\n",
    "\n",
    "It is given by:\n",
    "$\\text{NDWI} = \\frac{\\textrm{GREEN}-\\textrm{NIR}}{\\textrm{GREEN}+\\textrm{NIR}}$\n",
    "\n",
    "\n",
    "which for Sentinel-2 becomes:\n",
    "\n",
    "$\\text{NDWI} = \\frac{\\textrm{B3}-\\textrm{B8}}{\\textrm{B3}+\\textrm{B8}}$\n",
    "\n",
    "We are now going to test it, though we are using L1C data. Normally one would use L2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi = (dset.B3[n,ymin:ymax,xmin:xmax] -dset.B8[n,ymin:ymax,xmin:xmax])/(dset.B3[n,ymin:ymax,xmin:xmax] +dset.B8[n,ymin:ymax,xmin:xmax])\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(ndwi, interpolation='none', aspect='auto', extent = extent)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "This is learning where we as the computer to classify the area based on a given model. In this case we are going to use [scikit-learn](https://scikit-learn.org/stable/)\n",
    "and the method [K-means](https://scikit-learn.org/stable/modules/clustering.html#k-means) to cluster data. It is based on the minimising the variance in the cluster, though something called its intertia. The link above has an excellent explanation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # We are first going to make the dataset, which here is going to be rgb + NIR\n",
    "\n",
    "rgbn = np.dstack((dset.B4[n,ymin:ymax,xmin:xmax],dset.B3[n,ymin:ymax,xmin:xmax],\n",
    "      dset.B2[n,ymin:ymax,xmin:xmax],dset.B8[n,ymin:ymax,xmin:xmax]))\n",
    "\n",
    "w, h, d = original_shape = tuple(rgbn.shape)\n",
    "\n",
    "rgbn_2d = np.reshape(rgbn,(w*h,d))\n",
    "print(rgbn_2d.shape)\n",
    "# We select a small subset to fit on:\n",
    "rgbn_sample = skl.utils.shuffle(rgbn_2d, random_state=0, n_samples=1_000)\n",
    "\n",
    "# We are now going to ask for a certain number of clusters\n",
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(rgbn_sample)\n",
    "\n",
    "# Predict the labels for the whole image \n",
    "# (this could also be a new image, and can be reused on multiple images)\n",
    "\n",
    "labels = kmeans.predict(rgbn_2d)\n",
    "print(labels.shape)\n",
    "\n",
    "# Show the results\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(labels.reshape(w,h), interpolation='none', aspect='auto', extent = extent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "\n",
    "In contrast to unsupervised learning, in supervised learning we need to teach the algorithm what a given class looks like. \n",
    "We have a range of different algorithms to choose from, and it would be to much to go through them all. \n",
    "Here we choose to use a neural network, specifically \"Multi-layer Perceptron\" from scikit-learn. You can read more about it at [Neural network models (supervised)](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n",
    "\n",
    "There are much faster implmentations neural networks in deep learning architectures, but these require the use of GPUs and dedicated software (for instance [TensorFLow](https://www.tensorflow.org/) ). SNAP also has built in modules for supervised learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to define som areas to learn from. We are going to look at classifying into \n",
    "# four different types and we will be using the same dataset (rgbn) as for unsupervised classification\n",
    "\n",
    "wx=[500, 700]\n",
    "wy=[250, 500]\n",
    "\n",
    "water = rgbn[wx[0]:wx[1],wy[0]:wy[1],:]\n",
    "water = np.reshape(water,(water.shape[0]*water.shape[1],d)) # making it 2d\n",
    "\n",
    "tx=[560, 660]\n",
    "ty=[860, 910]\n",
    "\n",
    "trees = rgbn[tx[0]:tx[1],ty[0]:ty[1],:]\n",
    "trees = np.reshape(trees,(trees.shape[0]*trees.shape[1],d)) # making it 2d\n",
    "\n",
    "cx=[1185, 1225]\n",
    "cy=[690, 740]\n",
    "\n",
    "clouds = rgbn[cx[0]:cx[1],cy[0]:cy[1],:]\n",
    "clouds = np.reshape(clouds,(clouds.shape[0]*clouds.shape[1],d)) # making it 2d\n",
    "\n",
    "bx=[943, 970]\n",
    "by=[920, 945]\n",
    "\n",
    "build = rgbn[bx[0]:bx[1],by[0]:by[1],:]\n",
    "build = np.reshape(build,(build.shape[0]*build.shape[1],d)) # making it 2d\n",
    "\n",
    "\n",
    "\n",
    "def plot_rect(xlim, ylim, text, col):\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.add_patch(patches.Rectangle((xlim[0], ylim[0]), ylim[1]-ylim[0], xlim[1]-xlim[0], edgecolor=col, fill=False))\n",
    "    ax.annotate(text,(xlim[1]+10, ylim[0]+(ylim[1]-ylim[0])/2), color=col, ha='left', va='center')\n",
    "    \n",
    "\n",
    "# Show where the rectangles are\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(rgb, interpolation='none', aspect='equal')#, extent = extent) # Plotting it in x y coordinates and not lat lon\n",
    "plot_rect(wx, wy, \"Water\", \"red\")\n",
    "plot_rect(tx, ty, \"Trees\", \"white\")\n",
    "plot_rect(cx, cy, \"Clouds\", \"green\")\n",
    "plot_rect(bx, by, \"City\", \"black\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to use these to train the algorithm\n",
    "X = np.concatenate([water, trees, clouds, build])\n",
    "\n",
    "#Assigning labels 0 = water, 1 = trees, 2 = clouds, 3 = city\n",
    "y = np.concatenate([\n",
    "    np.zeros(water.shape[0]),\n",
    "    np.ones(trees.shape[0]),\n",
    "    np.ones(clouds.shape[0]) + 1,\n",
    "    np.ones(build.shape[0]) + 2])\n",
    "# \n",
    "print(X.shape,y.shape)\n",
    "# Initialise the neural network\n",
    "clf = MLPClassifier() # We are using default values\n",
    "clf.fit(X, y)\n",
    "\n",
    "# How many layers and outputs are we using:\n",
    "print(clf.n_layers_, clf.n_outputs_)\n",
    "\n",
    "labels_nn = clf.predict(rgbn_2d)\n",
    "print(labels_nn.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assigning colours to the different labels\n",
    "col_dict={0:\"blue\", # Sea\n",
    "          1:\"green\", # Trees\n",
    "          2:\"white\", # Clouds\n",
    "          3:\"black\"} # City\n",
    "\n",
    "\n",
    "cm = ListedColormap([col_dict[x] for x in col_dict.keys()])\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(labels_nn.reshape(w,h), interpolation='none', aspect='equal', cmap=cm)#, extent = extent,cmap=cm)\n",
    "cbar = plt.colorbar( orientation='horizontal',ticks=[3/8,2*3/4-3/8,3*3/4-3/8,4*3/4-3/8])\n",
    "cbar.ax.set_xticklabels(['Sea', 'Trees', 'Clouds', 'Houses'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
